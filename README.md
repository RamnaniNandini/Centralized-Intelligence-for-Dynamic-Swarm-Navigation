# Centralized-Intelligence-for-Dynamic-Swarm-Navigation
# Overview

This repository presents a dual-layered architecture for swarm navigation, tailored for controlling both large and small swarms of robots. The solution integrates advanced Reinforcement Learning (RL) strategies with real-time mapping, object detection, and dynamic obstacle avoidance, ensuring robust and adaptive navigation.

# Key Features
Dual-Layered Architecture:

Large Swarms: Controlled using a master-slave system for efficient task coordination.

Small Swarms: Operate autonomously for decentralized decision-making.
Advanced RL Strategies:

Proximal Policy Optimization (PPO): Ensures reliable and sample-efficient navigation in environments with frequently appearing/disappearing obstacles.
Twin Delayed Deep Deterministic Policy Gradient (TD3): Facilitates precise control and stability in tight spaces or scenarios with multiple dynamic obstacles.
# Real-Time Mapping and Object Detection:

LiDAR and cameras enable adaptive mapping of the environment.
Object identification and categorization (static vs. dynamic) are performed using the YOLOv8 Nano Object Detection Model.
# Shared Map Database:

A common map database is maintained, storing obstacle types and locations.
Implemented using MongoDB, ideal for handling real-time, document-based data generated by the robots.
# Methodology
## Mapping and Navigation:

Robots dynamically create maps of their surroundings using LiDAR and camera data.
Shared map data is stored in a MongoDB database for synchronized navigation.
## Reinforcement Learning (RL):

PPO: Guides robots through proper pathways while avoiding collisions.

TD3: Provides enhanced precision and control for complex maneuvers, such as navigating tight spaces.
Object Detection:

YOLOv8 Nano model is utilized for efficient object recognition and categorization.
Deployed on an NVIDIA Jetson platform for real-time processing.
# Dataset Preparation:

Dataset created using TurtleBot in a simulated environment.
Manual annotations and image augmentation techniques (scaling, cropping, etc.) were applied to improve generalization.
# Results
Achieved a 91% success rate in navigating dynamic environments with TD3.

Recorded 2500 reward points in just 500 episodes during RL training.

Accurate object detection and categorization with the YOLOv8 Nano model.
# Technology Stack
Reinforcement Learning: PPO, TD3

Object Detection: YOLOv8 Nano

Simulation: TurtleBot, NVIDIA Jetson

Mapping & Database: LiDAR, Camera, MongoDB

Programming Languages: Python

Frameworks and Libraries: PyTorch, TensorFlow, OpenCV
